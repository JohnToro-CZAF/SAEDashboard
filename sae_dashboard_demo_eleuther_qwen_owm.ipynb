{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Download SAE with SAE Lens.\n",
    "2. Create a dataset consistent with that SAE. \n",
    "3. Fold the SAE decoder norm weights so that feature activations are \"correct\".\n",
    "4. Estimate the activation normalization constant if needed, and fold it into the SAE weights.\n",
    "5. Run the SAE generator for the features you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import torch\n",
    "from sae_lens import SAE\n",
    "from transformers import AutoTokenizer\n",
    "from transformer_lens import HookedTransformer\n",
    "from sae_dashboard.sae_vis_data import SaeVisConfig\n",
    "from sae_dashboard.sae_vis_runner import SaeVisRunner\n",
    "from sae_dashboard.data_writing_fns import save_prompt_centric_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for displaying vis in Colab / notebook\n",
    "import webbrowser\n",
    "import http.server\n",
    "import socketserver\n",
    "import threading\n",
    "PORT = 8000\n",
    "def display_vis_inline(filename: str, height: int = 850):\n",
    "    '''\n",
    "    Displays the HTML files in Colab. Uses global `PORT` variable defined in prev cell, so that each\n",
    "    vis has a unique port without having to define a port within the function.\n",
    "    '''\n",
    "    webbrowser.open(filename);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Download / Initialize SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "model = HookedTransformer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\", dtype=\"float16\", device=device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-1.5B-Instruct\")\n",
    "sae, cfg_dict, sparsity = SAE.from_eleuther(\n",
    "    release=\"huypn16/sae-qwen-2.5-1.5B-OWM-16x\",  # see other options in sae_lens/pretrained_saes.yaml\n",
    "    sae_id=\"layers.14\",  # won't always be a hook point\n",
    "    device=device,\n",
    ")\n",
    "# fold w_dec norm so feature activations are accurate\n",
    "sae.fold_W_dec_norm()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get token dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens import ActivationsStore\n",
    "activations_store = ActivationsStore.from_sae(\n",
    "    model=model,\n",
    "    sae=sae,\n",
    "    streaming=True,\n",
    "    dataset=\"open-web-math/open-web-math\",\n",
    "    token_columns=[\"text\"],\n",
    "    store_batch_size_prompts=16,\n",
    "    n_batches_in_buffer=16,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "def get_tokens(\n",
    "    activations_store: ActivationsStore,\n",
    "    n_prompts: int,\n",
    "):\n",
    "    all_tokens_list = []\n",
    "    pbar = tqdm(range(n_prompts))\n",
    "    for _ in pbar:\n",
    "        batch_tokens = activations_store.get_batch_tokens()\n",
    "        batch_tokens = batch_tokens[torch.randperm(batch_tokens.shape[0])][\n",
    "            : batch_tokens.shape[0]\n",
    "        ]\n",
    "        all_tokens_list.append(batch_tokens)\n",
    "\n",
    "    all_tokens = torch.cat(all_tokens_list, dim=0)\n",
    "    all_tokens = all_tokens[torch.randperm(all_tokens.shape[0])]\n",
    "    return all_tokens\n",
    "\n",
    "# 1000 prompts is plenty for a demo.\n",
    "if os.path.exists(\"qwen_owm.pt\"):\n",
    "    token_dataset = torch.load(\"qwen_owm.pt\")\n",
    "else:\n",
    "    token_dataset = get_tokens(activations_store, n_prompts=1024)\n",
    "    torch.save(token_dataset, \"qwen_owm.pt\")\n",
    "\n",
    "print(tokenizer.decode(token_dataset[0][:32]))\n",
    "print(token_dataset.shape) # [store_batch_size_prompts * n_prompts, 1024]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 Evaluate the SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens import run_evals\n",
    "from sae_lens.evals import get_eval_everything_config\n",
    "\n",
    "eval_metrics = run_evals(\n",
    "    sae=sae,\n",
    "    activation_store=activations_store,\n",
    "    model=model,\n",
    "    eval_config=get_eval_everything_config(\n",
    "        batch_size_prompts=8,\n",
    "        n_eval_reconstruction_batches=10,\n",
    "        n_eval_sparsity_variance_batches=3,\n",
    "    )\n",
    ")\n",
    "print(json.dumps(eval_metrics, indent=4))\n",
    "# CE Loss score should be high for residual stream SAEs\n",
    "print(eval_metrics[\"metrics/ce_loss_score\"])\n",
    "# ce loss without SAE should be fairly low < 3.5 suggesting the Model is being run correctly\n",
    "print(eval_metrics[\"metrics/ce_loss_without_sae\"])\n",
    "# ce loss with SAE shouldn't be massively higher\n",
    "print(eval_metrics[\"metrics/ce_loss_with_sae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generate Feature Dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "# random features\n",
    "test_feature_idx_qwen = random.sample(range(sae.cfg.d_sae), 100)\n",
    "# test_feature_idx_llama = [21719]\n",
    "# test_feature_idx_llama = random.sample(range(1024), 2)\n",
    "# test_feature_idx_qwen = [1, 2, 3]\n",
    "# test_feature_idx_qwen =  [101, 345, 4087, 4297, 4410, 4411, 4444, 4782, 4783, 4877, 4954, 6460, 6551, 6878, 7384, 7410, 8303, 9321, 9775, 10327, 10738, 11302, 11594, 13107, 14068, 14344, 15023, 15311, 16451, 17808, 17975, 18038, 18312, 18758, 18923, 20166, 21021, 21719, 21792, 21850, 22720, 23602, 24219]\n",
    "# test_feature_idx_qwen = [200, 416, 694, 787, 837, 1189, 1262, 1265, 1418, 1536, 1879, 1908, 1941, 1948, 1993, 2073, 2363, 2365, 2388, 2489, 2536, 2701, 2722, 2981, 3390, 3499, 3779, 4274, 4627, 4812, 5980, 6000, 6133, 6454, 6650, 6809, 7115, 7503, 7597, 7836, 8042, 8454, 8694, 9655, 10000, 10046, 10372, 10466, 10509, 10605, 10800, 11501, 11551, 13075, 13357, 13371, 13724, 13793, 14715, 14841, 14986, 14996, 15303, 16754, 16852, 16882, 16887, 17110, 17186, 17313, 17394, 17430, 17438, 17996, 18090, 18256, 18451, 18540, 18613, 18992, 19281, 19298, 19664, 19985, 21002, 21558, 21874, 21967, 21968, 22083, 22679, 22765, 22928, 23296, 23317, 23423, 23545, 23609, 23682]\n",
    "# test_feature_idx_qwen = range(sae.cfg.d_sae)\n",
    "\n",
    "feature_vis_config_llama = SaeVisConfig(\n",
    "    hook_point=sae.cfg.hook_name,\n",
    "    features=test_feature_idx_qwen,\n",
    "    minibatch_size_features=100,\n",
    "    minibatch_size_tokens=256,  # this is number of prompts at a time.\n",
    "    verbose=True,\n",
    "    device=\"cuda\",\n",
    "    cache_dir=Path(\n",
    "        \"qwen25.layers.14_bs=256_nrows=16384\"\n",
    "    ),  # this will enable us to skip running the model for subsequent features.\n",
    "    dtype=\"bfloat16\",\n",
    ")\n",
    "\n",
    "data = SaeVisRunner(feature_vis_config_llama).run(\n",
    "    encoder=sae,  # type: ignore\n",
    "    model=model,\n",
    "    tokens=token_dataset[:8192],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_prompt_centric_vis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# prompt = \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 1000 * 2 - 1 ) * 412 - 2. Step 1: First, we minus 2 and 1\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mProblem:  Let $(a_1,b_1),$ $(a_2,b_2),$ $\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdots,$ $(a_n,b_n)$ be all the ordered pairs $(a,b)$ of complex numbers with $a^2+b^2\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mneq 0,$\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[a+\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;132;01m{10b}\u001b[39;00m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124ma^2+b^2}=5, \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mquad \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;132;01m{and}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mquad b+\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;132;01m{10a}\u001b[39;00m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124ma^2+b^2}=4.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]Find $a_1 + b_1 + a_2 + b_2 + \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdots + a_n + b_n.$ \u001b[39m\n\u001b[1;32m      5\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124m#### Step 7: If $a = \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;132;01m{5}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m,$ then \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m5/2}\u001b[39m\u001b[38;5;132;01m{b}\u001b[39;00m\u001b[38;5;124m = \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;132;01m{10}\u001b[39;00m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;132;01m{25}\u001b[39;00m\u001b[38;5;132;01m{4}\u001b[39;00m\u001b[38;5;124m + b^2}.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]. This simplifies to $4b^2 - 16b + 25 = 0.$  By the quadratic formula,\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[b = 2 \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mpm \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mfrac\u001b[39m\u001b[38;5;132;01m{3i}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 22\u001b[0m \u001b[43msave_prompt_centric_vis\u001b[49m(prompt\u001b[38;5;241m=\u001b[39mprompt, sae_vis_data\u001b[38;5;241m=\u001b[39mdata, filename\u001b[38;5;241m=\u001b[39mfilename)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_prompt_centric_vis' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = f\"qwen_owm.layers.14.math_toks=16384x1024.html\"\n",
    "# prompt = \"Solving the following mathematical problem. Problem: Calculate the following expression: (12 + 1000 * 2 - 1 ) * 412 - 2. Step 1: First, we minus 2 and 1\"\n",
    "prompt = \"\"\"Problem:  Let $(a_1,b_1),$ $(a_2,b_2),$ $\\dots,$ $(a_n,b_n)$ be all the ordered pairs $(a,b)$ of complex numbers with $a^2+b^2\\\\neq 0,$\n",
    "\\[a+\\\\frac{10b}{a^2+b^2}=5, \\quad \\\\text{and} \\quad b+\\\\frac{10a}{a^2+b^2}=4.\\]Find $a_1 + b_1 + a_2 + b_2 + \\dots + a_n + b_n.$ \n",
    "\n",
    "#### Step 1: If $a = 0,$ then $\\\\frac{10}{b} = 5,$ so $b = 2,$ which does not satisfy the second equation.\n",
    "\n",
    "#### Step 2: If $b = 0,$ then $\\\\frac{10}{a} = 4,$ so $a = \\\\frac{5}{2},$ which does not satisfy the first equation.\n",
    "\n",
    "#### Step 3: So, we can assume that both $a$ and $b$ are nonzero.\n",
    "\n",
    "#### Step 4: Then $\\\\frac{5 - a}{b} = \\\\frac{4 - b}{a} = \\\\frac{10}{a^2 + b^2}.$\n",
    "\n",
    "#### Step 5: \\[\\\\frac{5b - ab}{b^2} = \\\\frac{4a - ab}{a^2} = \\\\frac{10}{a^2 + b^2},\\]so\n",
    "\\[\\\\frac{4a + 5b - 2ab}{a^2 + b^2} = \\\\frac{10}{a^2 + b^2},\\]so $4a + 5b - 2ab = 10.$\n",
    "\n",
    "#### Step 6: Then $2ab - 4a - 5b + 10 = 0,$ which factors as $(2a - 5)(b - 2) = 0.$  Hence, $a = \\\\frac{5}{2}$ or $b = 2.$\n",
    "\n",
    "#### Step 7: If $a = \\\\frac{5}{2},$ then \\[\\\\frac{5/2}{b} = \\\\frac{10}{\\\\frac{25}{4} + b^2}.\\]. This simplifies to $4b^2 - 16b + 25 = 0.$  By the quadratic formula,\n",
    "\\[b = 2 \\pm \\\\frac{3i}{2}.\\]\"\"\"\n",
    "\n",
    "save_prompt_centric_vis(prompt=prompt, sae_vis_data=data, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_dashboard.data_writing_fns import save_feature_centric_vis\n",
    "\n",
    "filename = f\"qwen_owm.layers.14.math_toks=16384x1024.html\"\n",
    "save_feature_centric_vis(sae_vis_data=data, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
